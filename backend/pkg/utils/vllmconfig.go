package utils

import (
	"encoding/json"
	"flag"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
)

// ModelConfig å­˜å‚¨æ¨¡å‹çš„åŸºæœ¬é…ç½®
type ModelConfig struct {
	Name                  string  // æ¨¡å‹åç§°
	ParamsBillion         float64 // æ¨¡å‹å‚æ•°ï¼ˆåäº¿ï¼‰
	HiddenSize            int     // éšè—å±‚ç»´åº¦
	NumHiddenLayers       int     // éšè—å±‚æ•°
	NumAttentionHeads     int     // æ³¨æ„åŠ›å¤´æ•°
	MaxPositionEmbeddings int     // æœ€å¤§ä½ç½®ç¼–ç ï¼ˆä¸Šä¸‹æ–‡é•¿åº¦ï¼‰
	HeadDim               int     // æ¯ä¸ªå¤´çš„ç»´åº¦
	NumKeyValueHeads      int     // KVå¤´æ•°ï¼ˆç”¨äºGQAï¼‰
}

// GPUConfig å­˜å‚¨GPUé…ç½®
type GPUConfig struct {
	MemoryGB    float64 // GPUå†…å­˜ï¼ˆGBï¼‰
	Utilization float64 // å†…å­˜åˆ©ç”¨ç‡
	ReservedGB  float64 // ç³»ç»Ÿé¢„ç•™å†…å­˜ï¼ˆGBï¼‰
}

// VLLMConfig vLLMé…ç½®è¾“å‡º
type VLLMConfig struct {
	MaxModelLen         int     `json:"max_model_len"`          // æœ€å¤§æ¨¡å‹é•¿åº¦
	MaxNumSeqs          int     `json:"max_num_seqs"`           // æœ€å¤§å¹¶å‘åºåˆ—æ•°
	MaxNumBatchedTokens int     `json:"max_num_batched_tokens"` // æœ€å¤§æ‰¹å¤„ç†tokensæ•°
	GPUMemoryUtil       float64 `json:"gpu_memory_util"`        // GPUå†…å­˜åˆ©ç”¨ç‡
	SwapSpaceGB         int     `json:"swap_space_gb"`          // äº¤æ¢ç©ºé—´ï¼ˆGBï¼‰
	EnablePrefixCaching bool    `json:"enable_prefix_caching"`  // æ˜¯å¦å¯ç”¨å‰ç¼€ç¼“å­˜
	KVBlockSize         int     `json:"kv_block_size"`          // KVç¼“å­˜å—å¤§å°
}

// HuggingFaceConfig ä»config.jsonè¯»å–çš„åŸå§‹é…ç½®
type HuggingFaceConfig struct {
	Architectures         []string `json:"architectures,omitempty"`
	HiddenSize            int      `json:"hidden_size,omitempty"`
	NumHiddenLayers       int      `json:"num_hidden_layers,omitempty"`
	NumAttentionHeads     int      `json:"num_attention_heads,omitempty"`
	MaxPositionEmbeddings int      `json:"max_position_embeddings,omitempty"`
	IntermediateSize      int      `json:"intermediate_size,omitempty"`
	VocabSize             int      `json:"vocab_size,omitempty"`
	ModelType             string   `json:"model_type,omitempty"`
	TorchDtype            string   `json:"torch_dtype,omitempty"`
	NumKeyValueHeads      int      `json:"num_key_value_heads,omitempty"` // å¯¹äºGQAæ¨¡å‹
	RopeTheta             float64  `json:"rope_theta,omitempty"`
	SlidingWindow         int      `json:"sliding_window,omitempty"` // æ»‘åŠ¨çª—å£æ³¨æ„åŠ›
}

// CalculateConfigParams è®¡ç®—é…ç½®çš„è¾“å…¥å‚æ•°
type CalculateConfigParams struct {
	ModelNameOrPath string
	GPUMemoryGB     float64
	Mode            string
	GPUUtilization  float64
}

// CalculateVLLMConfig è®¡ç®—vLLMé…ç½® (API friendly version)
func CalculateVLLMConfig(params CalculateConfigParams) (VLLMConfig, ModelConfig, error) {
	// é»˜è®¤åˆ©ç”¨ç‡
	if params.GPUUtilization <= 0 {
		params.GPUUtilization = 0.9
	}

	// å¦‚æœå†…å­˜å°äº8GBä¸”åˆ©ç”¨ç‡ä¸ºé»˜è®¤å€¼0.9ï¼Œåˆ™è°ƒä½è‡³0.85ä»¥æ›´ä¿å®ˆ
	if params.GPUMemoryGB < 8 && params.GPUUtilization == 0.9 {
		params.GPUUtilization = 0.85
	}

	// å°è¯•åŠ è½½æ¨¡å‹é…ç½®
	modelConfig, err := loadModelConfig(params.ModelNameOrPath)
	if err != nil {
		log.Printf("è­¦å‘Š: æ— æ³•ä»é…ç½®è¯»å–æ¨¡å‹å‚æ•°: %v", err)
		log.Println("å°†å°è¯•ä»æ¨¡å‹åç§°ä¼°ç®—å‚æ•°...")
		modelConfig = EstimateModelConfigFromName(params.ModelNameOrPath)
	}

	// ç¡®ä¿æ¨¡å‹åç§°æ­£ç¡®
	if modelConfig.Name == "" {
		modelConfig.Name = params.ModelNameOrPath
	}

	// åˆ›å»ºGPUé…ç½®
	gpuConfig := GPUConfig{
		MemoryGB:    params.GPUMemoryGB,
		Utilization: params.GPUUtilization,
		ReservedGB:  1.0, // é»˜è®¤é¢„ç•™1GBç»™ç³»ç»Ÿ
	}

	// æ ¹æ®æ¨¡å¼è®¡ç®—ä¼˜åŒ–é…ç½®
	var vllmConfig VLLMConfig
	switch strings.ToLower(params.Mode) {
	case "max_token":
		vllmConfig = CalculateMaxTokenConfig(modelConfig, gpuConfig)
	case "max_concurrency":
		vllmConfig = CalculateMaxConcurrencyConfig(modelConfig, gpuConfig)
	case "balanced":
		fallthrough
	default:
		vllmConfig = CalculateBalancedConfig(modelConfig, gpuConfig)
	}

	// æ€»æ˜¯å¯ç”¨å‰ç¼€ç¼“å­˜ï¼ˆå¯¹æ€§èƒ½æœ‰ç›Šï¼‰
	vllmConfig.EnablePrefixCaching = true

	return vllmConfig, modelConfig, nil
}

func main() {
	// è§£æå‘½ä»¤è¡Œå‚æ•°
	model := flag.String("model", "", "æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„ï¼ˆæ ¼å¼ï¼šauthor/model-name æˆ– /path/to/modelï¼‰")
	gpuMemoryStr := flag.String("gpu_memory", "8G", "GPUå†…å­˜ï¼ˆå¦‚ï¼š8Gã€16Gã€24Gï¼‰")
	mode := flag.String("mode", "balanced", "ä¼˜åŒ–æ¨¡å¼ï¼šmax_tokenï¼ˆæœ€å¤§é•¿åº¦ï¼‰ã€max_concurrencyï¼ˆæœ€å¤§å¹¶å‘ï¼‰ã€balancedï¼ˆå¹³è¡¡ï¼‰")
	utilization := flag.Float64("utilization", 0.9, "GPUå†…å­˜åˆ©ç”¨ç‡ï¼ˆ0.0-1.0ï¼Œå°æ˜¾å­˜<8Gæ—¶è‡ªåŠ¨è°ƒæ•´ä¸º0.85ï¼‰")
	enableSwap := flag.Bool("enable_swap", false, "æ˜¯å¦å¯ç”¨äº¤æ¢ç©ºé—´")

	flag.Parse()

	if *model == "" {
		fmt.Println("é”™è¯¯: å¿…é¡»æŒ‡å®š --model å‚æ•°")
		fmt.Println("ç”¨æ³•ç¤ºä¾‹:")
		fmt.Println("  vllm-optimizer.exe --model \"D:\\models\\huggingface\\hub\\Qwen3-1.7B\" --gpu_memory 8G")
		fmt.Println("  vllm-optimizer.exe --model Qwen/Qwen3-1.7B --gpu_memory 8G")
		os.Exit(1)
	}

	// è§£æGPUå†…å­˜å­—ç¬¦ä¸²
	gpuMemoryGB, err := parseMemoryString(*gpuMemoryStr)
	if err != nil {
		log.Fatalf("è§£æGPUå†…å­˜é”™è¯¯: %v", err)
	}

	// ä½¿ç”¨å…¬å…±å‡½æ•°è®¡ç®—
	params := CalculateConfigParams{
		ModelNameOrPath: *model,
		GPUMemoryGB:     gpuMemoryGB,
		Mode:            *mode,
		GPUUtilization:  *utilization,
	}

	vllmConfig, modelConfig, err := CalculateVLLMConfig(params)
	if err != nil {
		log.Fatalf("è®¡ç®—é…ç½®å¤±è´¥: %v", err)
	}

	// å¦‚æœå¯ç”¨äº¤æ¢ç©ºé—´ï¼Œè®¾ç½®äº¤æ¢ç©ºé—´å¤§å° (CLIç‰¹æœ‰é€»è¾‘)
	if *enableSwap && gpuMemoryGB < 16 {
		vllmConfig.SwapSpaceGB = 8
	}

	// åˆ›å»ºGPUé…ç½®ç”¨äºæ‰“å° (Recover GPU Config for printing)
	gpuConfig := GPUConfig{
		MemoryGB:    gpuMemoryGB,
		Utilization: *utilization,
		ReservedGB:  1.0,
	}

	// è¾“å‡ºé…ç½®
	printConfig(modelConfig, gpuConfig, vllmConfig, *mode)

	// è¾“å‡ºvLLMå‘½ä»¤è¡Œ
	printVLLMCommand(*model, vllmConfig)
}

// parseMemoryString è§£æå†…å­˜å­—ç¬¦ä¸²ï¼ˆå¦‚ "8G" -> 8.0ï¼‰
func parseMemoryString(memoryStr string) (float64, error) {
	re := regexp.MustCompile(`^(\d+(?:\.\d+)?)\s*([GT]?B?)$`)
	matches := re.FindStringSubmatch(strings.ToUpper(memoryStr))

	if matches == nil {
		return 0, fmt.Errorf("æ— æ•ˆçš„å†…å­˜æ ¼å¼: %sï¼Œè¯·ä½¿ç”¨å¦‚ '8G', '16GB', '24G' çš„æ ¼å¼", memoryStr)
	}

	value, err := strconv.ParseFloat(matches[1], 64)
	if err != nil {
		return 0, err
	}

	unit := matches[2]
	if strings.Contains(unit, "T") {
		value *= 1024 // TBè½¬GB
	}

	return value, nil
}

// loadModelConfig å°è¯•ä»æ¨¡å‹é…ç½®æ–‡ä»¶ä¸­è¯»å–æ¨¡å‹é…ç½®
func loadModelConfig(modelPath string) (ModelConfig, error) {
	var config ModelConfig

	// å°è¯•ä¸åŒçš„é…ç½®è·¯å¾„
	var configPaths []string

	// é¦–å…ˆï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„ä½œä¸ºç›®å½•ï¼ŒæŸ¥æ‰¾config.json
	configPaths = append(configPaths, filepath.Join(modelPath, "config.json"))

	// å¦‚æœè·¯å¾„åŒ…å«"/"ï¼Œå¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•ä¸‹æŸ¥æ‰¾
	if strings.Contains(modelPath, "/") || strings.Contains(modelPath, "\\") {
		// å·²ç»æ˜¯è·¯å¾„æ ¼å¼ï¼Œä¿ç•™åŸæ ·
	} else {
		// å¯èƒ½æ˜¯æ¨¡å‹åç§°ï¼Œå°è¯•åœ¨HuggingFaceç¼“å­˜ä¸­æŸ¥æ‰¾
		home, err := os.UserHomeDir()
		if err == nil {
			// å°è¯•æ ‡å‡†HuggingFaceç¼“å­˜è·¯å¾„
			hfCachePath := filepath.Join(home, ".cache", "huggingface", "hub")
			modelCachePath := strings.ReplaceAll(modelPath, "/", "--")
			configPaths = append(configPaths,
				filepath.Join(hfCachePath, "models--"+modelCachePath, "snapshots", "latest", "config.json"),
				filepath.Join(hfCachePath, "models--"+modelCachePath, "config.json"),
			)
		}

		// å°è¯• backend/deployments/models ç›®å½• (For Project Structure)
		configPaths = append(configPaths, filepath.Join("backend", "deployments", "models", modelPath, "config.json"))
		configPaths = append(configPaths, filepath.Join("..", "backend", "deployments", "models", modelPath, "config.json"))
		// Fix for running tests from pkg/utils
		configPaths = append(configPaths, filepath.Join("..", "..", "deployments", "models", modelPath, "config.json"))
		// å¦‚æœè¿è¡Œåœ¨backendç›®å½•
		configPaths = append(configPaths, filepath.Join("deployments", "models", modelPath, "config.json"))
		// å¦‚æœè¿è¡Œåœ¨æ ¹ç›®å½•
		configPaths = append(configPaths, filepath.Join("models", modelPath, "config.json"))

		// ä¹Ÿå°è¯•åœ¨å½“å‰ç›®å½•ä¸‹æŸ¥æ‰¾
		configPaths = append(configPaths, filepath.Join(".", modelPath, "config.json"))
	}

	// å°è¯•è¯»å–é…ç½®æ–‡ä»¶
	var configData []byte
	var configFile string
	var lastError error

	for _, path := range configPaths {
		log.Printf("å°è¯•è¯»å–é…ç½®æ–‡ä»¶: %s", path)
		if data, err := os.ReadFile(path); err == nil {
			configData = data
			configFile = path
			log.Printf("æˆåŠŸä» %s è¯»å–é…ç½®æ–‡ä»¶", configFile)
			break
		} else {
			lastError = err
			log.Printf("è¯»å– %s å¤±è´¥: %v", path, err)
		}
	}

	if configData == nil {
		return config, fmt.Errorf("æ— æ³•æ‰¾åˆ°æ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œæœ€åé”™è¯¯: %v", lastError)
	}

	// è§£æJSONé…ç½®
	var hfConfig HuggingFaceConfig
	if err := json.Unmarshal(configData, &hfConfig); err != nil {
		return config, fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// å¡«å……æ¨¡å‹é…ç½®
	config.HiddenSize = hfConfig.HiddenSize
	config.NumHiddenLayers = hfConfig.NumHiddenLayers
	config.NumAttentionHeads = hfConfig.NumAttentionHeads
	config.MaxPositionEmbeddings = hfConfig.MaxPositionEmbeddings
	config.NumKeyValueHeads = hfConfig.NumKeyValueHeads

	// å°è¯•ä»è·¯å¾„ä¸­æå–åç§° (e.g. "Qwen/Qwen2.5-7B" from path)
	if modelPath != "" {
		// If modelPath looks like a path (contains slashes), use the last part as name
		baseName := filepath.Base(modelPath)
		if baseName == "latest" || baseName == "." {
			// If path ends in 'latest' or '.', try the parent
			baseName = filepath.Base(filepath.Dir(modelPath))
		}
		// Clean up "models--" prefix from huggingface cache
		baseName = strings.TrimPrefix(baseName, "models--")
		baseName = strings.ReplaceAll(baseName, "--", "/")
		
		config.Name = baseName
	}

	// è®¡ç®—æ¯ä¸ªå¤´çš„ç»´åº¦
	if hfConfig.NumAttentionHeads > 0 {
		config.HeadDim = hfConfig.HiddenSize / hfConfig.NumAttentionHeads
	} else {
		config.HeadDim = 128 // é»˜è®¤å€¼
	}

	// ä¼°ç®—æ¨¡å‹å‚æ•°å¤§å°ï¼ˆåäº¿ï¼‰
	config.ParamsBillion = estimateModelParams(hfConfig)

	log.Printf("æ¨¡å‹é…ç½®: hidden_size=%d, num_hidden_layers=%d, num_attention_heads=%d, max_position_embeddings=%d, params=%.1fB",
		config.HiddenSize, config.NumHiddenLayers, config.NumAttentionHeads,
		config.MaxPositionEmbeddings, config.ParamsBillion)

	return config, nil
}

// estimateModelParams æ ¹æ®æ¨¡å‹é…ç½®ä¼°ç®—å‚æ•°æ•°é‡ï¼ˆåäº¿ï¼‰
func estimateModelParams(hfConfig HuggingFaceConfig) float64 {
	// å¦‚æœæ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œå°è¯•ä»æ¨¡å‹åç§°ä¸­æå–
	if hfConfig.HiddenSize == 0 || hfConfig.NumHiddenLayers == 0 {
		return extractParamsFromName(hfConfig.ModelType)
	}

	// ä½¿ç”¨å…¬å¼ä¼°ç®—ï¼šå‚æ•° â‰ˆ vocab_size * hidden_size + num_layers * (12 * hidden_size^2)
	vocabSize := hfConfig.VocabSize
	if vocabSize == 0 {
		vocabSize = 100000 // é»˜è®¤è¯æ±‡è¡¨å¤§å°
	}

	hiddenSize := float64(hfConfig.HiddenSize)
	numLayers := float64(hfConfig.NumHiddenLayers)

	// ä¼°ç®—åµŒå…¥å±‚å‚æ•°
	embeddingParams := float64(vocabSize) * hiddenSize

	// ä¼°ç®—Transformerå±‚å‚æ•°ï¼ˆæ¯å±‚çº¦12*hidden_size^2ï¼‰
	// è¿™æ˜¯è¿‘ä¼¼å…¬å¼ï¼šæ¯å±‚æœ‰è‡ªæ³¨æ„åŠ›å±‚ï¼ˆ4*h^2ï¼‰å’Œå‰é¦ˆå±‚ï¼ˆ8*h^2ï¼‰
	transformerParamsPerLayer := 12.0 * hiddenSize * hiddenSize
	transformerParams := numLayers * transformerParamsPerLayer

	// æ€»å‚æ•°ï¼ˆè½¬æ¢ä¸ºåäº¿ï¼‰
	totalParams := (embeddingParams + transformerParams) / 1e9

	// å››èˆäº”å…¥åˆ°ä¸€ä½å°æ•°
	return totalParams
}

// extractParamsFromName ä»æ¨¡å‹åç§°ä¸­æå–å‚æ•°å¤§å°ï¼ˆåäº¿ï¼‰
func extractParamsFromName(modelName string) float64 {
	modelNameLower := strings.ToLower(modelName)

	// å¸¸è§æ¨¡å‹åç§°æ¨¡å¼
	patterns := []*regexp.Regexp{
		regexp.MustCompile(`(\d+(?:\.\d+)?)[Bb]`),    // åŒ¹é… "1.7B", "7B", "13B"
		regexp.MustCompile(`-(\d+)b`),                // åŒ¹é… "-7b", "-13b"
		regexp.MustCompile(`(\d+)[Bb]`),              // åŒ¹é… "7B", "13B"
		regexp.MustCompile(`(\d+(?:\.\d+)?)b`),       // åŒ¹é… "1.7b", "7b"
		regexp.MustCompile(`qwen3-(\d+(?:\.\d+)?)b`), // åŒ¹é… "qwen3-1.7b"
	}

	for _, pattern := range patterns {
		matches := pattern.FindStringSubmatch(modelNameLower)
		if matches != nil {
			params, err := strconv.ParseFloat(matches[1], 64)
			if err == nil {
				return params
			}
		}
	}

	// æ ¹æ®å¸¸è§æ¨¡å‹åç§°çŒœæµ‹
	if strings.Contains(modelNameLower, "tiny") {
		return 0.1
	} else if strings.Contains(modelNameLower, "small") {
		return 0.3
	} else if strings.Contains(modelNameLower, "medium") {
		return 1.5
	} else if strings.Contains(modelNameLower, "large") {
		return 7.0
	} else if strings.Contains(modelNameLower, "xlarge") {
		return 13.0
	} else if strings.Contains(modelNameLower, "2b") || strings.Contains(modelNameLower, "2.7b") {
		return 2.7
	} else if strings.Contains(modelNameLower, "3b") {
		return 3.0
	} else if strings.Contains(modelNameLower, "6b") || strings.Contains(modelNameLower, "6.7b") {
		return 6.7
	} else if strings.Contains(modelNameLower, "8b") || strings.Contains(modelNameLower, "7b") {
		return 7.0
	} else if strings.Contains(modelNameLower, "13b") {
		return 13.0
	} else if strings.Contains(modelNameLower, "34b") || strings.Contains(modelNameLower, "32b") {
		return 34.0
	} else if strings.Contains(modelNameLower, "70b") {
		return 70.0
	}

	// Qwenç³»åˆ—çš„ç‰¹æ®Šå¤„ç†
	if strings.Contains(modelNameLower, "qwen3") {
		if strings.Contains(modelNameLower, "0.5") {
			return 0.5
		} else if strings.Contains(modelNameLower, "1.5") {
			return 1.5
		} else if strings.Contains(modelNameLower, "1.7") {
			return 1.7
		} else if strings.Contains(modelNameLower, "4") {
			return 4.0
		} else if strings.Contains(modelNameLower, "7") {
			return 7.0
		} else if strings.Contains(modelNameLower, "14") {
			return 14.0
		} else if strings.Contains(modelNameLower, "32") {
			return 32.0
		} else if strings.Contains(modelNameLower, "72") {
			return 72.0
		}
	}

	return 7.0 // é»˜è®¤å€¼
}

// EstimateModelConfigFromName ä»æ¨¡å‹åç§°ä¼°ç®—æ¨¡å‹é…ç½®
func EstimateModelConfigFromName(modelName string) ModelConfig {
	paramsBillion := extractParamsFromName(modelName)

	// æ ¹æ®å‚æ•°å¤§å°ä¼°ç®—é…ç½®
	var hiddenSize, numLayers, numHeads, maxPosEmbeddings int

	switch {
	case paramsBillion <= 1.0:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 1024, 12, 12, 8192
	case paramsBillion <= 1.7:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 1536, 16, 12, 131072 // Qwen3-1.7Bçš„é…ç½®
	case paramsBillion <= 3.0:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 2048, 24, 16, 32768
	case paramsBillion <= 7.0:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 4096, 32, 32, 32768
	case paramsBillion <= 13.0:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 5120, 40, 40, 32768
	case paramsBillion <= 34.0:
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 8192, 60, 64, 131072
	default: // 70B+
		hiddenSize, numLayers, numHeads, maxPosEmbeddings = 8192, 80, 64, 131072
	}

	// Qwenç³»åˆ—çš„ç‰¹æ®Šå¤„ç†
	modelNameLower := strings.ToLower(modelName)
	if strings.Contains(modelNameLower, "qwen") {
		if strings.Contains(modelNameLower, "qwen3") {
			// Qwen3ç³»åˆ—é€šå¸¸æ”¯æŒé•¿ä¸Šä¸‹æ–‡
			maxPosEmbeddings = 131072
		} else {
			maxPosEmbeddings = 32768
		}
	}

	return ModelConfig{
		ParamsBillion:         paramsBillion,
		HiddenSize:            hiddenSize,
		NumHiddenLayers:       numLayers,
		NumAttentionHeads:     numHeads,
		MaxPositionEmbeddings: maxPosEmbeddings,
		HeadDim:               hiddenSize / numHeads,
		NumKeyValueHeads:      numHeads, // é»˜è®¤ä¸æ³¨æ„åŠ›å¤´æ•°ç›¸åŒ
	}
}

// calculateModelWeightMemory è®¡ç®—æ¨¡å‹æƒé‡å†…å­˜ï¼ˆGBï¼ŒFP16ç²¾åº¦ï¼‰
func calculateModelWeightMemory(model ModelConfig) float64 {
	// FP16ç²¾åº¦ï¼Œæ¯ä¸ªå‚æ•°2å­—èŠ‚
	return model.ParamsBillion * 2.0
}

// calculateKVCachePerToken è®¡ç®—æ¯ä¸ªtokençš„KVç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
func calculateKVCachePerToken(model ModelConfig) float64 {
	// KVç¼“å­˜å¤§å° = 2 * num_layers * kv_channels * head_dim * 2 (bytes, for float16)
	// æ³¨æ„ï¼šå¯¹äºGQAæ¨¡å‹ï¼Œkv_channelså¯èƒ½å°äºnum_attention_heads
	kvChannels := model.NumKeyValueHeads
	if kvChannels == 0 {
		kvChannels = model.NumAttentionHeads
	}

	return 2.0 * float64(model.NumHiddenLayers) * float64(kvChannels) * float64(model.HeadDim) * 2.0
}

// CalculateMaxTokenConfig è®¡ç®—æœ€å¤§åŒ–åºåˆ—é•¿åº¦çš„é…ç½®
func CalculateMaxTokenConfig(model ModelConfig, gpu GPUConfig) VLLMConfig {
	// å¯ç”¨GPUå†…å­˜ï¼ˆGBï¼‰
	availableMemoryGB := gpu.MemoryGB * gpu.Utilization

	// æ¨¡å‹æƒé‡å†…å­˜ï¼ˆGBï¼‰
	weightMemoryGB := calculateModelWeightMemory(model)

	// é¢„ç•™ç³»ç»Ÿå†…å­˜ï¼ˆGBï¼‰
	systemReservedGB := gpu.ReservedGB

	// å¯ç”¨äºKVç¼“å­˜çš„å†…å­˜ï¼ˆGBï¼‰
	kvCacheMemoryGB := availableMemoryGB - weightMemoryGB - systemReservedGB

	if kvCacheMemoryGB < 0.5 { // è‡³å°‘éœ€è¦0.5GBç”¨äºKVç¼“å­˜
		log.Printf("è­¦å‘Š: GPUå†…å­˜ä¸è¶³ï¼ŒKVç¼“å­˜å¯ç”¨å†…å­˜ä»… %.2fGB", kvCacheMemoryGB)
		kvCacheMemoryGB = 0.5
	}

	// è®¡ç®—æ¯ä¸ªtokençš„KVç¼“å­˜ï¼ˆå­—èŠ‚ï¼‰
	kvCachePerTokenBytes := calculateKVCachePerToken(model)

	// è½¬æ¢ä¸ºGB
	kvCachePerTokenGB := kvCachePerTokenBytes / (1024 * 1024 * 1024)

	// è®¡ç®—æœ€å¤§æ”¯æŒçš„tokenæ•°
	maxTokens := int(kvCacheMemoryGB / kvCachePerTokenGB)

	// é™åˆ¶ä¸è¶…è¿‡æ¨¡å‹åŸç”Ÿæœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
	if model.MaxPositionEmbeddings > 0 && maxTokens > model.MaxPositionEmbeddings {
		maxTokens = model.MaxPositionEmbeddings
	}

	// ç¡®ä¿è‡³å°‘æœ‰æœ€å°é•¿åº¦
	minTokens := 2048
	if maxTokens < minTokens {
		maxTokens = minTokens
	}

	// è®¾ç½®å¹¶å‘æ•°ï¼ˆæœ€å¤§åŒ–é•¿åº¦æ—¶ï¼Œå¹¶å‘æ•°è¾ƒä½ï¼‰
	maxConcurrency := 1
	if kvCacheMemoryGB > 4.0 { // å¦‚æœæœ‰è¶³å¤Ÿå†…å­˜ï¼Œå¯ä»¥ç¨å¾®å¢åŠ å¹¶å‘
		maxConcurrency = 2
	}

	// è®¡ç®—æ‰¹å¤„ç†å¤§å°ï¼ˆåŸºäºåºåˆ—é•¿åº¦ï¼‰
	batchTokens := maxTokens
	if batchTokens > 32768 {
		batchTokens = 32768 // é™åˆ¶æ‰¹å¤„ç†å¤§å°
	}

	return VLLMConfig{
		MaxModelLen:         maxTokens,
		MaxNumSeqs:          maxConcurrency,
		MaxNumBatchedTokens: batchTokens,
		GPUMemoryUtil:       gpu.Utilization,
		KVBlockSize:         16,
	}
}

// CalculateMaxConcurrencyConfig è®¡ç®—æœ€å¤§åŒ–å¹¶å‘æ•°çš„é…ç½®
func CalculateMaxConcurrencyConfig(model ModelConfig, gpu GPUConfig) VLLMConfig {
	// å¯ç”¨GPUå†…å­˜ï¼ˆGBï¼‰
	availableMemoryGB := gpu.MemoryGB * gpu.Utilization

	// æ¨¡å‹æƒé‡å†…å­˜ï¼ˆGBï¼‰
	weightMemoryGB := calculateModelWeightMemory(model)

	// é¢„ç•™ç³»ç»Ÿå†…å­˜ï¼ˆGBï¼‰
	systemReservedGB := gpu.ReservedGB

	// å¯ç”¨äºKVç¼“å­˜çš„å†…å­˜ï¼ˆGBï¼‰
	kvCacheMemoryGB := availableMemoryGB - weightMemoryGB - systemReservedGB

	if kvCacheMemoryGB < 1.0 { // è‡³å°‘éœ€è¦1GBç”¨äºKVç¼“å­˜
		log.Printf("è­¦å‘Š: GPUå†…å­˜ä¸è¶³ï¼ŒKVç¼“å­˜å¯ç”¨å†…å­˜ä»… %.2fGB", kvCacheMemoryGB)
		kvCacheMemoryGB = 1.0
	}

	// è®¡ç®—æ¯ä¸ªtokençš„KVç¼“å­˜ï¼ˆGBï¼‰
	kvCachePerTokenBytes := calculateKVCachePerToken(model)
	kvCachePerTokenGB := kvCachePerTokenBytes / (1024 * 1024 * 1024)

	// è®¾ç½®åˆç†çš„åºåˆ—é•¿åº¦ï¼ˆé’ˆå¯¹å¹¶å‘ä¼˜åŒ–ï¼‰
	seqLen := 4096
	if gpu.MemoryGB < 8 {
		seqLen = 2048
	} else if gpu.MemoryGB > 16 {
		seqLen = 8192
	}

	// é™åˆ¶ä¸è¶…è¿‡æ¨¡å‹åŸç”Ÿæœ€å¤§é•¿åº¦
	if model.MaxPositionEmbeddings > 0 && seqLen > model.MaxPositionEmbeddings {
		seqLen = model.MaxPositionEmbeddings
	}

	// è®¡ç®—æœ€å¤§å¹¶å‘æ•°
	kvCachePerSeqGB := kvCachePerTokenGB * float64(seqLen)
	maxConcurrency := int(kvCacheMemoryGB / kvCachePerSeqGB)

	// ç¡®ä¿æœ€å°å’Œæœ€å¤§å¹¶å‘æ•°
	if maxConcurrency < 1 {
		maxConcurrency = 1
	} else if maxConcurrency > 256 {
		maxConcurrency = 256 // vLLMé»˜è®¤æœ€å¤§å€¼
	}

	// è®¡ç®—æ‰¹å¤„ç†å¤§å°ï¼ˆåŸºäºå¹¶å‘æ•°ï¼‰
	batchTokens := seqLen * maxConcurrency
	if batchTokens > 32768 {
		batchTokens = 32768
	}

	return VLLMConfig{
		MaxModelLen:         seqLen,
		MaxNumSeqs:          maxConcurrency,
		MaxNumBatchedTokens: batchTokens,
		GPUMemoryUtil:       gpu.Utilization,
		KVBlockSize:         16,
	}
}

// CalculateBalancedConfig è®¡ç®—å¹³è¡¡é…ç½®
func CalculateBalancedConfig(model ModelConfig, gpu GPUConfig) VLLMConfig {
	// å¯ç”¨GPUå†…å­˜ï¼ˆGBï¼‰
	availableMemoryGB := gpu.MemoryGB * gpu.Utilization

	// æ¨¡å‹æƒé‡å†…å­˜ï¼ˆGBï¼‰
	weightMemoryGB := calculateModelWeightMemory(model)

	// é¢„ç•™ç³»ç»Ÿå†…å­˜ï¼ˆGBï¼‰
	systemReservedGB := gpu.ReservedGB

	// å¯ç”¨äºKVç¼“å­˜çš„å†…å­˜ï¼ˆGBï¼‰
	kvCacheMemoryGB := availableMemoryGB - weightMemoryGB - systemReservedGB

	if kvCacheMemoryGB < 1.0 {
		log.Printf("è­¦å‘Š: GPUå†…å­˜ä¸è¶³ï¼ŒKVç¼“å­˜å¯ç”¨å†…å­˜ä»… %.2fGB", kvCacheMemoryGB)
		kvCacheMemoryGB = 1.0
	}

	// è®¡ç®—æ¯ä¸ªtokençš„KVç¼“å­˜ï¼ˆGBï¼‰
	kvCachePerTokenBytes := calculateKVCachePerToken(model)
	kvCachePerTokenGB := kvCachePerTokenBytes / (1024 * 1024 * 1024)

	// æ ¹æ®GPUå†…å­˜ç¡®å®šåºåˆ—é•¿åº¦
	var seqLen int
	if gpu.MemoryGB < 6 {
		seqLen = 2048
	} else if gpu.MemoryGB < 12 {
		seqLen = 4096
	} else if gpu.MemoryGB < 24 {
		seqLen = 8192
	} else {
		seqLen = 16384
	}

	// é™åˆ¶ä¸è¶…è¿‡æ¨¡å‹åŸç”Ÿæœ€å¤§é•¿åº¦
	if model.MaxPositionEmbeddings > 0 && seqLen > model.MaxPositionEmbeddings {
		seqLen = model.MaxPositionEmbeddings
	}

	// è®¡ç®—å¯ä»¥æ”¯æŒçš„å¹¶å‘æ•°
	kvCachePerSeqGB := kvCachePerTokenGB * float64(seqLen)
	maxConcurrency := int(kvCacheMemoryGB / kvCachePerSeqGB)

	// è°ƒæ•´å¹¶å‘æ•°ä»¥è·å¾—å¹³è¡¡
	if maxConcurrency > 8 {
		maxConcurrency = 8
	} else if maxConcurrency < 2 {
		maxConcurrency = 2
	}

	// è®¡ç®—æ‰¹å¤„ç†å¤§å°
	batchTokens := seqLen * 2 // å¹³è¡¡æ¨¡å¼ä¸‹ï¼Œæ‰¹å¤„ç†å¤§å°ä¸º2ä¸ªåºåˆ—
	if batchTokens > 16384 {
		batchTokens = 16384
	}

	return VLLMConfig{
		MaxModelLen:         seqLen,
		MaxNumSeqs:          maxConcurrency,
		MaxNumBatchedTokens: batchTokens,
		GPUMemoryUtil:       gpu.Utilization,
		KVBlockSize:         16,
	}
}

// printConfig æ‰“å°é…ç½®è¯¦æƒ…
func printConfig(model ModelConfig, gpu GPUConfig, vllm VLLMConfig, mode string) {
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘                 vLLM é…ç½®ä¼˜åŒ–å·¥å…·                        â•‘")
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Printf("â•‘ æ¨¡å‹: %-50s â•‘\n", model.Name)
	fmt.Printf("â•‘ GPUå†…å­˜: %.1fGB | æ¨¡å¼: %-15s | åˆ©ç”¨ç‡: %.2f â•‘\n",
		gpu.MemoryGB, mode, gpu.Utilization)
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

	// æ¨¡å‹å‚æ•°ä¿¡æ¯
	fmt.Println("â•‘                        æ¨¡å‹ä¿¡æ¯                          â•‘")
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Printf("â•‘ â€¢ å‚æ•°å¤§å°:        %6.1f B                        â•‘\n", model.ParamsBillion)
	fmt.Printf("â•‘ â€¢ éšè—å±‚ç»´åº¦:      %6d                          â•‘\n", model.HiddenSize)
	fmt.Printf("â•‘ â€¢ å±‚æ•°:            %6d                          â•‘\n", model.NumHiddenLayers)
	fmt.Printf("â•‘ â€¢ æ³¨æ„åŠ›å¤´æ•°:      %6d                          â•‘\n", model.NumAttentionHeads)
	if model.NumKeyValueHeads > 0 {
		fmt.Printf("â•‘ â€¢ KVå¤´æ•°:          %6d                          â•‘\n", model.NumKeyValueHeads)
	}
	if model.MaxPositionEmbeddings > 0 {
		fmt.Printf("â•‘ â€¢ åŸç”Ÿæœ€å¤§é•¿åº¦:    %6d                          â•‘\n", model.MaxPositionEmbeddings)
	}

	// è®¡ç®—å†…å­˜ä½¿ç”¨è¯¦æƒ…
	weightMemoryGB := calculateModelWeightMemory(model)
	kvCachePerTokenBytes := calculateKVCachePerToken(model)
	kvCachePerTokenGB := kvCachePerTokenBytes / (1024 * 1024 * 1024)
	totalKVCacheGB := kvCachePerTokenGB * float64(vllm.MaxModelLen) * float64(vllm.MaxNumSeqs)
	availableMemoryGB := gpu.MemoryGB * gpu.Utilization
	otherUsageGB := availableMemoryGB - weightMemoryGB - totalKVCacheGB

	// ç¡®ä¿otherUsageGBä¸ä¸ºè´Ÿæ•°
	if otherUsageGB < 0 {
		otherUsageGB = 0
	}

	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Println("â•‘                        å†…å­˜åˆ†é…                          â•‘")
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Printf("â•‘ â€¢ æ¨¡å‹æƒé‡:         %6.2f GB (FP16)                 â•‘\n", weightMemoryGB)
	fmt.Printf("â•‘ â€¢ KVç¼“å­˜/Token:     %6.2f KB                        â•‘\n", kvCachePerTokenBytes/1024)
	fmt.Printf("â•‘ â€¢ æ€»KVç¼“å­˜:         %6.2f GB                        â•‘\n", totalKVCacheGB)
	fmt.Printf("â•‘ â€¢ ç³»ç»ŸåŠå…¶ä»–:       %6.2f GB                        â•‘\n", otherUsageGB)

	totalUsedGB := weightMemoryGB + totalKVCacheGB + otherUsageGB
	usagePercent := (totalUsedGB / gpu.MemoryGB) * 100
	fmt.Printf("â•‘ â€¢ æ€»ä½¿ç”¨:           %6.2f GB / %5.1f GB (%.0f%%)      â•‘\n",
		totalUsedGB, gpu.MemoryGB, usagePercent)

	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Println("â•‘                   æ¨è vLLM å‚æ•°                         â•‘")
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Printf("â•‘ --max-model-len          %-10d (æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦)       â•‘\n", vllm.MaxModelLen)
	fmt.Printf("â•‘ --max-num-seqs           %-10d (æœ€å¤§å¹¶å‘è¯·æ±‚æ•°)       â•‘\n", vllm.MaxNumSeqs)
	fmt.Printf("â•‘ --max-num-batched-tokens %-10d (æ‰¹å¤„ç†tokensæ•°)      â•‘\n", vllm.MaxNumBatchedTokens)
	fmt.Printf("â•‘ --gpu-memory-utilization %-10.2f (GPUå†…å­˜åˆ©ç”¨ç‡)      â•‘\n", vllm.GPUMemoryUtil)

	if vllm.SwapSpaceGB > 0 {
		fmt.Printf("â•‘ --swap-space            %-10d (äº¤æ¢ç©ºé—´GB)         â•‘\n", vllm.SwapSpaceGB)
	}

	if vllm.EnablePrefixCaching {
		fmt.Printf("â•‘ --enable-prefix-caching                (å¯ç”¨å‰ç¼€ç¼“å­˜) â•‘\n")
	}

	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
}

// printVLLMCommand è¾“å‡ºå®Œæ•´çš„vLLMå‘½ä»¤
func printVLLMCommand(model string, config VLLMConfig) {
	fmt.Println("\nğŸš€ ç”Ÿæˆçš„ vLLM å¯åŠ¨å‘½ä»¤:")
	fmt.Printf("vllm serve %s \\\n", model)
	fmt.Printf("    --max-model-len %d \\\n", config.MaxModelLen)
	fmt.Printf("    --max-num-seqs %d \\\n", config.MaxNumSeqs)
	fmt.Printf("    --max-num-batched-tokens %d \\\n", config.MaxNumBatchedTokens)
	fmt.Printf("    --gpu-memory-utilization %.2f", config.GPUMemoryUtil)

	if config.SwapSpaceGB > 0 {
		fmt.Printf(" \\\n    --swap-space %d", config.SwapSpaceGB)
	}

	if config.EnablePrefixCaching {
		fmt.Printf(" \\\n    --enable-prefix-caching")
	}

	fmt.Println()

	// ä½¿ç”¨å»ºè®®
	fmt.Println("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
	if config.MaxModelLen > 32768 {
		fmt.Println("â€¢ ä½ é…ç½®äº†è¶…é•¿ä¸Šä¸‹æ–‡(>32K)ï¼Œå»ºè®®ä½¿ç”¨æµå¼å“åº”é¿å…è¶…æ—¶")
		fmt.Println("â€¢ è€ƒè™‘å¯ç”¨ --enable-chunked-prefill å‚æ•°ä»¥æ›´å¥½åœ°å¤„ç†é•¿åºåˆ—")
	}
	if config.MaxNumSeqs < 4 {
		fmt.Println("â€¢ å¹¶å‘æ•°è¾ƒä½ï¼Œé€‚åˆå¤„ç†å°‘é‡é•¿æ–‡æ¡£ä»»åŠ¡")
		fmt.Println("â€¢ å¯¹äºæ‰¹é‡å¤„ç†ï¼Œè€ƒè™‘å¢åŠ  --swap-space æˆ–å‡å°‘åºåˆ—é•¿åº¦")
	} else if config.MaxNumSeqs > 16 {
		fmt.Println("â€¢ é«˜å¹¶å‘é…ç½®ï¼Œé€‚åˆèŠå¤©APIæœåŠ¡")
		fmt.Println("â€¢ ç›‘æ§GPUå†…å­˜ä½¿ç”¨ï¼Œé¿å…OOMé”™è¯¯")
	} else {
		fmt.Println("â€¢ å¹¶å‘æ•°é€‚ä¸­ï¼Œé€‚åˆé€šç”¨APIæœåŠ¡")
	}
	if config.SwapSpaceGB > 0 {
		fmt.Println("â€¢ å·²å¯ç”¨äº¤æ¢ç©ºé—´ï¼Œå½“GPUå†…å­˜ä¸è¶³æ—¶ä¼šä½¿ç”¨ç³»ç»Ÿå†…å­˜")
		fmt.Println("  æ³¨æ„ï¼šè¿™ä¼šæ˜¾è‘—é™ä½æ€§èƒ½ï¼Œä»…ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
	}

	// æ€§èƒ½ä¼˜åŒ–å»ºè®®
	fmt.Println("\nğŸ”§ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
	if config.MaxNumBatchedTokens > 32768 {
		fmt.Println("â€¢ è€ƒè™‘é™ä½ --max-num-batched-tokens ä»¥æ”¹å–„TTFTï¼ˆé¦–æ¬¡tokenæ—¶é—´ï¼‰")
	}
	if config.MaxNumSeqs > 8 && config.MaxModelLen > 8192 {
		fmt.Println("â€¢ é•¿ä¸Šä¸‹æ–‡+é«˜å¹¶å‘å¯èƒ½å‹åŠ›è¾ƒå¤§ï¼Œè€ƒè™‘ä½¿ç”¨ --quantization awq é‡åŒ–")
	}
}
